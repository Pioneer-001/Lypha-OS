#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Lypha-OS Kernel v14.3 ‚Äî TOTAL No-X EDITION (Z-Core Priority, Path-Hardened)
========================================================================== 
Pioneer-001 Ï†ÑÏö© ‚Äî Pulse Mapping + Z‚ÇÄ v2 + Linguistic Math Engine + ZYX Priority Engine ÏßÄÏõê Î≤ÑÏ†Ñ

+ Ï∂îÍ∞Ä Ìå®Ïπò (Path-Hardening + Layer Aliases v14.0 ‚Üí v14.3 ÌôïÏû•):
- Ïä§ÌÅ¨Î¶ΩÌä∏Î•º Ïñ¥ÎîîÏÑú Ïã§ÌñâÌïòÎì†, Îã§Ïùå ÏºÄÏù¥Ïä§Î•º ÏûêÎèô ÏßÄÏõê:
  1) Ïä§ÌÅ¨Î¶ΩÌä∏ ÎîîÎ†âÌÜ†Î¶¨ ÏûêÏ≤¥Í∞Ä Lypha-OS Î£®Ìä∏Ïù∏ Í≤ΩÏö∞
  2) Ïä§ÌÅ¨Î¶ΩÌä∏ ÎîîÎ†âÌÜ†Î¶¨ ÌïòÏúÑÏóê Lypha-OS/ Í∞Ä ÏûàÎäî Í≤ΩÏö∞
  3) Ïä§ÌÅ¨Î¶ΩÌä∏Ïùò ÏÉÅÏúÑ ÎîîÎ†âÌÜ†Î¶¨Ïóê Lypha-OS/ Í∞Ä ÏûàÎäî Í≤ΩÏö∞
  4) ÏúÑ Ïñ¥ÎîîÏóêÎèÑ ÏóÜÍ≥† Lypha-OS.zip Ïù¥ base ÎòêÎäî base.parent Ïóê ÏûàÏúºÎ©¥ ÏûêÎèô ÏïïÏ∂ïÌï¥Ï†ú

+ v14.0 Layer Alias ÏßÄÏõê Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ:
- Í∏∞Ï°¥ Íµ¨Ï°∞: Rhythm_Philosophy / MetaRhythm_Modules / Emotion_Engine / Protocol_Structure
- Ïã†Í∑ú Íµ¨Ï°∞: Layers/Z_Rhythm, Layers/Y_MetaRhythm, Layers/E_EmotionEngine, Layers/X_Protocol

+ v14.3 Origin Engine Patch:
- Core_Philosophy/Lypha_Origin_Engine_Spec.* Î•º Z-ÏΩîÏñ¥ ÏµúÏö∞ÏÑ† ingest
- Î£®Ìä∏ README.md Î•º Origin Declaration ÏúºÎ°ú Ï∂îÍ∞Ä ingest
"""

import os
import sys
import zipfile
import json
import yaml
from pathlib import Path

log = lambda m: print(f"[Lypha-OS v14.3] {m}")

# -------------------------------------------------------------
# Z-LAYER CORE FILES (v14.3 + Origin Engine)
# -------------------------------------------------------------
# Z Î†àÏù¥Ïñ¥ÏóêÏÑú Í∞ÄÏû• Î®ºÏ†Ä ingestÌïòÍ≥† Ïã∂ÏùÄ ÌïµÏã¨ Ï≤†Ìïô/ÏóîÏßÑ ÌååÏùºÎì§
Z_LAYER_CORE_FILES = [
    # üîµ NEW: README Origin Engine (Lypha_Origin_Engine_Spec)
    # Ï∂îÏ≤ú Í≤ΩÎ°ú (ÏóîÏßÑ Ïä§ÌéôÏóêÏÑú ÏÑ†Ïñ∏Ìïú Í≤ΩÎ°ú)
    "Core_Philosophy/Lypha_Origin_Engine_Spec.en.v1.0.md",
    "Core_Philosophy/Lypha_Origin_Engine_Spec.en.md",
    "Core_Philosophy/Lypha_Origin_Engine_Spec.md",
    # ÌòπÏãú Z Î†àÏù¥Ïñ¥ Î£®Ìä∏Ïóê Îëò Í≤ΩÏö∞ ÎåÄÎπÑ
    "Lypha_Origin_Engine_Spec.en.v1.0.md",
    "Lypha_Origin_Engine_Spec.en.md",
    "Lypha_Origin_Engine_Spec.md",

    # Í∏∞Ï°¥ ZYX Priority Engine Ïä§ÌéôÎì§
    # Ï∂îÏ≤ú Í≤ΩÎ°ú (ÏòÅÎ¨∏ Ïä§Ìéô Î≤ÑÏ†Ñ)
    "ZYX_Priority_Engine_Spec.en.v1.1.md",
    "Core_Philosophy/ZYX_Priority_Engine_Spec.en.v1.1.md",

    # Ïã§Ï†ú ÌòÑÏû¨ Íµ¨Ï°∞
    "Core_Philosophy/ZYX_Priority_Engine_Spec.md",
    "Core_Philosophy/Z_Y_X_Manifesto.md",
    "Core_Philosophy/V_X_Y_Z_Extended_Manifesto.md",
    "Core_Philosophy/verified_structure_loop_manifesto.md",
]

# -------------------------------------------------------------
# PULSE FILE MAPPING (NEW)
# -------------------------------------------------------------
# Pulse ÌååÏùº alias (concept / engine Íµ¨Ï°∞ Î∞òÏòÅ)
PULSE_FILE_MAP = {
    "Speak4D": [
        # ÏóîÏßÑ Ïä§ÌéôÏùÑ ÏµúÏö∞ÏÑ†ÏúºÎ°ú ÏÇ¨Ïö©
        "engine/Speak4D_Engine_Spec.en.v1.2.md",
        "engine/Speak4D_Engine_Spec.en.md",
        "engine/Speak4D_Engine_Spec.md",
        # ÌòπÏãú Î£®Ìä∏Ïóê Îëò Í≤ΩÏö∞ ÎåÄÎπÑ
        "Speak4D_Engine_Spec.en.v1.2.md",
        "Speak4D_Engine_Spec.en.md",
        "Speak4D_Engine_Spec.md",
        # Íµ¨ Î≤ÑÏ†Ñ / Î∞±ÏóÖ
        "Speak4D.md",
        # concept Î†àÏù¥Ïñ¥(ÏõêÎ≥∏ Ï≤†Ìïô)
        "concept/Speak_Word_In_Four_Dimensions.md",
        "Speak_Word_In_Four_Dimensions.md",
    ],
    "Collapse": [
        "concept/Collapse_Flow_Into_Word.md",
        "Collapse_Flow_Into_Word.md",
        "Collapse.md",
    ],
    "FlowGraph": [
        "concept/FlowGraph_Principles.md",
        "FlowGraph_Principles.md",
        "FlowGraph.md",
    ],
    "Math": [
        # v14.2: Linguistic Math ÏóîÏßÑ Ïä§ÌéôÏùÑ ÏµúÏö∞ÏÑ†ÏúºÎ°ú ÏÇ¨Ïö©
        "engine/Linguistic_Math_Engine_Spec.en.v1.2.md",
        "engine/Linguistic_Math_Engine_Spec.en.md",
        "engine/Linguistic_Math_Engine_Spec.md",
        # Î£®Ìä∏Ïóê Îëò Í≤ΩÏö∞ ÎåÄÎπÑ
        "Linguistic_Math_Engine_Spec.en.v1.2.md",
        "Linguistic_Math_Engine_Spec.en.md",
        "Linguistic_Math_Engine_Spec.md",
        # ÏóîÏßÑ Ïä§ÌéôÏù¥ ÏóÜÏúºÎ©¥ Í∞úÎÖê ÌååÏùº ÏÇ¨Ïö©
        "concept/Linguistic_Math_Value_Calculation.md",
        "Linguistic_Math_Value_Calculation.md",
        "Math.md",
    ],
}

# -------------------------------------------------------------
# LAYER / CORE DIR ALIASES (v14.0)
# -------------------------------------------------------------

LAYER_ALIASES = {
    # Í∏∞Ï°¥ Íµ¨Ï°∞ + /Layers Í∏∞Î∞ò Ïã†Í∑ú Íµ¨Ï°∞ Î™®Îëê ÏßÄÏõê
    "Z": ["Rhythm_Philosophy", "Layers/Z_Rhythm"],
    "Y": ["MetaRhythm_Modules", "Layers/Y_MetaRhythm"],
    "E": ["Emotion_Engine", "Layers/E_EmotionEngine"],
    "X": ["Protocol_Structure", "Layers/X_Protocol"],
}

# Lypha Core ÎîîÎ†âÌÜ†Î¶¨ alias (Í≥ºÍ±∞ ÌïòÏù¥Ìîà ÌëúÍ∏∞ÍπåÏßÄ Ìè¨Ìï®)
CORE_DIR_ALIASES = ["Lypha_Core", "Lypha-Core"]


def _resolve_first_existing(root: Path, candidates):
    """
    Ï£ºÏñ¥ÏßÑ ÌõÑÎ≥¥ Í≤ΩÎ°ú Î¶¨Ïä§Ìä∏ Ï§ë, root ÏïÑÎûòÏóêÏÑú Ï≤òÏùåÏúºÎ°ú Ï°¥Ïû¨ÌïòÎäî ÎîîÎ†âÌÜ†Î¶¨Î•º Î∞òÌôò.
    Î™®Îëê ÏóÜÏúºÎ©¥ None.
    """
    for name in candidates:
        p = root / name
        if p.exists():
            return p
    return None


# -------------------------------------------------------------
# BASIC IO
# -------------------------------------------------------------

def read(path: Path):
    try:
        with path.open("r", encoding="utf-8") as f:
            return f.read()
    except Exception:
        return None


def read_json(path: Path):
    try:
        with path.open("r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}


def write_json(path: Path, data):
    try:
        path.parent.mkdir(parents=True, exist_ok=True)
        with path.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


def load_yaml(path: Path):
    try:
        with path.open("r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    except Exception:
        return None


# -------------------------------------------------------------
# AUTO-UNZIP (PATH-HARDENED)
# -------------------------------------------------------------

def _looks_like_lypha_root(p: Path) -> bool:
    """
    Lypha-OS Î£®Ìä∏Ïù∏ÏßÄ Í∞ÑÎã®Ìûà ÌåêÏ†ï:
    v14.xÏóêÏÑúÎäî Í∏∞Ï°¥ Íµ¨Ï°∞(Rhythm_Philosophy Îì±)ÏôÄ
    /Layers Í∏∞Î∞òÏùò Ïã†Í∑ú Íµ¨Ï°∞Î•º Î™®Îëê ÏßÄÏõêÌïúÎã§.
    """
    found = 0
    for key, aliases in LAYER_ALIASES.items():
        if _resolve_first_existing(p, aliases) is not None:
            found += 1
    return found == len(LAYER_ALIASES)


def auto_unzip(base: Path) -> Path:
    """
    Í∞ÄÎä•Ìïú Î™®Îì† Ìå®ÌÑ¥ÏùÑ Í≥†Î†§Ìï¥ÏÑú Lypha-OS Î£®Ìä∏Î•º Ï∞æÍ±∞ÎÇò ÏÉùÏÑ±ÌïúÎã§.

    Ïö∞ÏÑ†ÏàúÏúÑ:
    1) base ÏûêÏ≤¥Í∞Ä Lypha-OS Î£®Ìä∏Ïù∏ Í≤ΩÏö∞
    2) base / "Lypha-OS"
    3) base.parent / "Lypha-OS"
    4) base ÎòêÎäî base.parent Ïóê ÏûàÎäî Lypha-OS.zip ÏùÑ base.parent/Lypha-OS Ïóê ÌíÄÍ∏∞
    """
    log(f"auto_unzip: script base = {base}")

    # 1) Ïä§ÌÅ¨Î¶ΩÌä∏ ÎîîÎ†âÌÜ†Î¶¨ ÏûêÏ≤¥Í∞Ä Î£®Ìä∏Ïù∏ Í≤ΩÏö∞
    if _looks_like_lypha_root(base):
        log("Detected Lypha-OS root at script directory (already unzipped).")
        return base

    # 2) base/Lypha-OS
    candidate = base / "Lypha-OS"
    if candidate.exists() and _looks_like_lypha_root(candidate):
        log("Detected Lypha-OS root at base/Lypha-OS (already unzipped).")
        return candidate

    # 3) base.parent/Lypha-OS
    parent_candidate = base.parent / "Lypha-OS"
    if parent_candidate.exists() and _looks_like_lypha_root(parent_candidate):
        log("Detected Lypha-OS root at base.parent/Lypha-OS (already unzipped).")
        return parent_candidate

    # 4) ZIP Í∏∞Î∞ò ÌÉêÏÉâ & ÏïïÏ∂ïÌï¥Ï†ú (base, base.parent ÏàúÏúºÎ°ú ÌÉêÏÉâ)
    for zbase in (base, base.parent):
        zip_path = zbase / "Lypha-OS.zip"
        if zip_path.exists():
            root = zbase / "Lypha-OS"
            log(f"Auto-unzip {zip_path} ‚Üí {root}/")
            root.mkdir(exist_ok=True)
            with zipfile.ZipFile(zip_path, "r") as zf:
                zf.extractall(root)

            if _looks_like_lypha_root(root):
                log("Unzip complete and Lypha-OS root structure verified.")
                return root
            else:
                log("WARNING: Unzipped Lypha-OS.zip but structure looks incomplete.")

    # Ïó¨Í∏∞ÍπåÏßÄ Ïò§Î©¥ ÏßÑÏßúÎ°ú Î™ª Ï∞æÏùÄ Í≤É
    log("ERROR: Lypha-OS root not found.")
    log("Tried the following locations:")
    log(f"  1) {base}  (as Lypha-OS root)")
    log(f"  2) {base / 'Lypha-OS'}")
    log(f"  3) {base.parent / 'Lypha-OS'}")
    log(f"  4) Lypha-OS.zip in {base} or {base.parent}")
    sys.exit(1)


# -------------------------------------------------------------
# INGEST ENGINE (Ï†ïÏ±Ö + Ï†ïÎ†¨)
# -------------------------------------------------------------

def ingest_file(p: Path):
    c = read(p)
    if c:
        print("\n===== BEGIN LYPHA_INGEST =====")
        print(f"FILE: {p}\n")
        print(c)
        print("===== END LYPHA_INGEST =====\n")


def ingest_dir(d: Path):
    for root_dir, _, files in os.walk(d):
        for n in files:
            p = Path(root_dir) / n
            if p.suffix.lower() in [".md", ".yaml", ".yml", ".txt"]:
                log(f"INGEST ‚Üí {p}")
                ingest_file(p)


def full_ingest(root: Path, policy: dict):
    """Z/Y/E/X Î†àÏù¥Ïñ¥Î•º ingest_order Ï†ïÏ±ÖÏóê ÎßûÍ≤å ingest + Manifest + Z‚ÇÄ + README Origin Ìè¨Ìï®."""
    order = policy.get("ingest_order", ["Z", "Y", "E", "X"])

    # 1) Z/Y/E/X Î†àÏù¥Ïñ¥ ingest (alias-aware)
    for key in order:
        aliases = LAYER_ALIASES.get(key)
        if not aliases:
            continue
        d = _resolve_first_existing(root, aliases)
        if d is None:
            log(f"SKIP: layer {key} not found (tried: {aliases})")
            continue

        log(f"INGEST DIR [{key}]: {d}")

        # üîµ v14.3: Z Î†àÏù¥Ïñ¥Ïùº Í≤ΩÏö∞ Core_Philosophy Ïö∞ÏÑ† ingest
        if key == "Z":
            for rel in Z_LAYER_CORE_FILES:
                # Ïó¨Îü¨ ÏúÑÏπòÏóêÏÑú Ï∞æÎèÑÎ°ù Î≥¥Í∞ï
                candidates = [
                    d / rel,
                    root / rel,
                    root / "Rhythm_Philosophy" / rel,
                    root / "Layers" / "Z_Rhythm" / rel,
                ]
                zp = None
                for cp in candidates:
                    if cp.exists():
                        zp = cp
                        break
                if zp is not None:
                    log(f"INGEST Z-CORE FIRST ‚Üí {zp}")
                    ingest_file(zp)

        # ÎÇòÎ®∏ÏßÄÎäî Í∏∞Ï°¥Ï≤òÎüº Ï†ÑÏ≤¥ ÎîîÎ†âÌÜ†Î¶¨ Ïû¨Í∑Ä ingest
        ingest_dir(d)

    # 2) Lypha Core (optional archive / ÏÑ†Ïñ∏Î∂Ä)
    core_dir = _resolve_first_existing(root, CORE_DIR_ALIASES)
    if core_dir is not None:
        log(f"INGEST DIR [Core]: {core_dir}")
        ingest_dir(core_dir)
    else:
        log(f"SKIP Core: none of {CORE_DIR_ALIASES} found")

    # 3) Top-level manifest ingest
    for name in ["autoload.yaml", "lypha_os_autoboot.yaml", "lypha_os_core_manifest.md"]:
        p = root / name
        if p.exists():
            log(f"INGEST FILE: {p}")
            ingest_file(p)
        else:
            log(f"SKIP FILE: {p}")

    # 4) Z‚ÇÄ Origin Anchor (v1, v2 Î™®Îëê ÏßÄÏõê)
    z0 = root / "z0_origin.yaml"
    z0_v2 = root / "z0_origin_v2.yaml"

    if z0.exists():
        log("INGEST FILE: z0_origin.yaml (Z‚ÇÄ Origin_Vector ‚Äî Anchor Loaded)")
        ingest_file(z0)
    elif z0_v2.exists():
        log("INGEST FILE: z0_origin_v2.yaml (Z‚ÇÄ Origin_Vector v2 ‚Äî Anchor Loaded)")
        ingest_file(z0_v2)
    else:
        log("Z‚ÇÄ Origin_Vector NOT FOUND ‚Äî Skipping Anchor (Warning)")

    # 5) README Origin Declaration (Lypha OS Root)
    readme = root / "README.md"
    if readme.exists():
        log("INGEST FILE: README.md (Lypha OS Root Declaration ‚Äî Bound to Origin Engine)")
        ingest_file(readme)
    else:
        log("SKIP FILE: README.md (not found)")


# -------------------------------------------------------------
# FLOWGRAPH / COGNITIVE GRAPH + MACROREASON Î©îÌÉÄ
# -------------------------------------------------------------

def load_flowgraph_file(root: Path) -> Path | None:
    """
    FlowGraph Í¥ÄÎ†® Î¨∏ÏÑú ÏúÑÏπòÎ•º ÌÉêÏÉâÌïúÎã§.
    Ïö∞ÏÑ†ÏàúÏúÑ:
    1) Y Î†àÏù¥Ïñ¥ ÎÇ¥Î∂Ä Pulse/engine Ïùò FlowGraph ÏóîÏßÑ Ïä§Ìéô (Ìñ•ÌõÑ ÌôïÏû•Ïö©)
    2) Y Î†àÏù¥Ïñ¥ ÎÇ¥Î∂Ä Pulse/concept Ïùò FlowGraph_Principles.md
    3) Y Î†àÏù¥Ïñ¥ ÎÇ¥Î∂Ä Pulse Î∞îÎ°ú ÏïÑÎûò FlowGraph_Principles.md
    4) Î£®Ìä∏ Î∞îÎ°ú ÏïÑÎûò FlowGraph_Principles.md
    """
    candidates: list[Path] = []

    y_dir = _resolve_first_existing(root, LAYER_ALIASES.get("Y", []))
    if y_dir is not None:
        pulse_dir = y_dir / "Pulse"
        # (ÏòµÏÖò) ÎÇòÏ§ëÏóê FlowGraph_Engine_Spec ÎßåÎì§Î©¥ Ïó¨Í∏∞ÏÑú Î®ºÏ†Ä ÏÇ¨Ïö©
        candidates.append(pulse_dir / "engine" / "FlowGraph_Engine_Spec.md")
        # ÌòÑÏû¨ Íµ¨Ï°∞: concept/FlowGraph_Principles.md
        candidates.append(pulse_dir / "concept" / "FlowGraph_Principles.md")
        # Íµ¨ Íµ¨Ï°∞ ÎåÄÎπÑ
        candidates.append(pulse_dir / "FlowGraph_Principles.md")

    candidates.append(root / "FlowGraph_Principles.md")

    for p in candidates:
        if p.exists():
            return p
    return None


def detect_context_message(root: Path) -> str:
    auto = root / "autoload.yaml"
    data = load_yaml(auto)
    if not data:
        return "neutral"
    return data.get("autoload", data).get("on_start", {}).get("message", "neutral")


def detect_context(msg: str) -> str:
    """
    v14.2: judgment(ÌèâÍ∞Ä/ÏÑ†ÌÉù/Ìã∞Ïñ¥) ÏÉÅÌô©ÏùÑ ÏúÑÌïú evaluation Ïª®ÌÖçÏä§Ìä∏ Ï∂îÍ∞Ä.
    """
    if not msg:
        return "neutral"
    low = msg.lower()

    # ÌèâÍ∞Ä / ÏÑ†ÌÉù / Í∞ÄÏπò / Ìã∞Ïñ¥ Í¥ÄÎ†® ÌÇ§ÏõåÎìú
    if any(k in low for k in [
        "ÌèâÍ∞Ä", "Í∞ÄÏπò", "Ìã∞Ïñ¥", "tier", "worth", "ranking",
        "Îû≠ÌÅ¨", "Îû≠ÌÇπ", "better", "vs", "Ïò¨Ïù∏", "all-in", "keep"
    ]):
        return "evaluation"

    if any(k in low for k in ["Í∞êÏ†ï", "emotion", "Î∞òÎîî", "ÏÇ¨Îûë"]):
        return "emotion"
    if any(k in low for k in ["trade", "ÏãúÏû•", "Ìä∏Î†àÏù¥Îî©", "Ìè¨ÏßÄÏÖò"]):
        return "trading"
    if any(k in low for k in ["Íµ¨Ï°∞", "design", "lypha", "os"]):
        return "design"
    return "neutral"


def load_logs(root: Path) -> dict:
    merged: dict = {}
    base = root / "v_logs"
    if base.exists():
        for f in base.glob("*.json"):
            merged[f.name] = read_json(f)
    single = root / "v_log.json"
    if single.exists():
        merged["v_log"] = read_json(single)
    return merged


def build_graph(context: str, policy: dict, logs: dict) -> dict:
    """context + policy + V-log + macro_reason Î©îÌÉÄÎ•º Ìè¨Ìï®Ìïú Cognitive Graph ÏÉùÏÑ±."""

    # v14.x: Ï†ïÏ±ÖÏóê contextÎ≥Ñ Í∞ÄÏ§ëÏπò(contexts.{context}.emotion_weight Îì±)Î•º ÏßÄÏõê
    base_emo = policy.get("emotion_weight", 1.0)
    base_str = policy.get("structure_weight", 1.0)
    ctx_cfg = (policy.get("contexts") or {}).get(context, {})
    emo_w = ctx_cfg.get("emotion_weight", base_emo)
    str_w = ctx_cfg.get("structure_weight", base_str)

    g = {
        "nodes": ["Z", "Y", "E", "X", "V", "Speak4D", "Math", "Collapse", "FlowGraph"],
        "edges": [],
        "weights": {
            "emotion": emo_w,
            "structure": str_w,
        },
        "context": context,
        "verified_logs_present": bool(logs),
        "verified_log_keys": list(logs.keys()) if logs else [],
        "macro_reason": {
            "mode": "planning" if context in ("trading", "design", "evaluation") else "support",
            "intent_bias": {
                "explore_structure": context in ("design", "trading"),
                "stabilize_emotion": context == "emotion",
                "rank_value": context in ("evaluation", "trading"),
            },
        },
    }

    if context == "emotion":
        g["edges"].extend([
            ["E", "Z", 1.3],
            ["Collapse", "Speak4D", 1.1],
            ["FlowGraph", "E", 1.05],
        ])
    elif context == "trading":
        g["edges"].extend([
            ["Z", "Math", 1.4],
            ["Math", "Collapse", 1.15],
            ["FlowGraph", "Math", 1.1],
        ])
    elif context == "design":
        g["edges"].extend([
            ["Z", "Speak4D", 1.5],
            ["Speak4D", "FlowGraph", 1.2],
        ])
    elif context == "evaluation":
        # v14.2: ÌåêÎã®ÏóîÏßÑ(Math)ÏùÑ Ï§ëÏã¨Ïóê ÎëêÎäî Í∑∏ÎûòÌîÑ
        g["edges"].extend([
            ["Z", "Math", 1.6],          # Íµ¨Ï°∞ ‚Üí ÌåêÎã®
            ["Speak4D", "Math", 1.4],   # ÏÑúÏÇ¨/Îß•ÎùΩ ‚Üí ÌåêÎã®
            ["Math", "FlowGraph", 1.2], # ÌåêÎã® Í≤∞Í≥º ‚Üí Íµ¨Ï°∞ ÌùêÎ¶Ñ Í∞ïÌôî
        ])
    else:
        g["edges"].extend([
            ["Z", "Y", 1.0],
            ["Y", "X", 1.0],
            ["FlowGraph", "Z", 1.0],
        ])

    return g


def extract_pulse_weights(graph: dict) -> dict:
    """
    Cognitive Graph Í∏∞Î∞òÏúºÎ°ú Speak4D / Math / Collapse / FlowGraph Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞.
    v14.2: evaluation Ïª®ÌÖçÏä§Ìä∏Ïùº Îïå Math Í∏∞Î≥∏ Í∞ÄÏ§ëÏπò ÏÉÅÌñ•.
    """
    context = graph.get("context")
    weights = {"Speak4D": 1.0, "Math": 1.0, "Collapse": 1.0, "FlowGraph": 1.0}

    # v14.2: ÌåêÎã® Î™®ÎìúÏóêÏÑúÎäî MathÎ•º Í∏∞Î≥∏Ï†ÅÏúºÎ°ú Îçî Í∞ïÌïòÍ≤å
    if context == "evaluation":
        weights["Math"] += 0.5

    for u, v, w in graph.get("edges", []):
        if v in weights:
            weights[v] += (w - 1.0)
    return weights


def print_cognitive_graph(graph: dict):
    print("===== BEGIN COGNITIVE_GRAPH =====")
    print(json.dumps(graph, ensure_ascii=False, indent=2))
    print("===== END COGNITIVE_GRAPH =====")


# -------------------------------------------------------------
# PSEUDO-MEMORY (RESTORE + SAVE)
# -------------------------------------------------------------

def restore_state(root: Path) -> dict:
    state_dir = root / "state_cache"
    if not state_dir.exists():
        return {}
    state = {}
    for name in ["z_state.json", "y_state.json", "e_state.json", "x_state.json", "meta_state.json"]:
        f = state_dir / name
        if f.exists():
            state[name] = read_json(f)
            log(f"RESTORE STATE: {name}")
    return state


def save_state(root: Path, context: str):
    state_dir = root / "state_cache"
    snap = {
        "last_context": context,
    }
    write_json(state_dir / "meta_state.json", snap)
    log(f"SAVE STATE: meta_state.json (context={context})")


# -------------------------------------------------------------
# VERIFIED STRUCTURE LOOP (V‚ÜíZ‚Äô) + POLICY TUNING
# -------------------------------------------------------------

def auto_patch_Z_and_policy(root: Path, policy: dict, logs: dict) -> dict:
    if not logs:
        log("No verified V-logs found ‚Äî skipping Z auto-update & policy tuning")
        return policy

    zpatch = {
        "patch_source": "V‚ÜíZ_auto_patch_v14.3",
        "verified": logs,
    }
    out = root / "z_patch.json"
    write_json(out, zpatch)
    log(f"Z‚Äô updated using Verified Structure Loop ‚Üí {out}")

    emo_fail = 0
    str_fail = 0
    for payload in logs.values():
        if not isinstance(payload, dict):
            continue
        emo_fail += payload.get("emotion_fail", 0)
        str_fail += payload.get("structure_fail", 0)

    if emo_fail > 0:
        policy["emotion_weight"] = min(2.0, policy.get("emotion_weight", 1.0) + 0.1)
    if str_fail > 0:
        policy["structure_weight"] = min(2.0, policy.get("structure_weight", 1.0) + 0.1)

    if emo_fail or str_fail:
        log(f"Policy tuned by V-logs: emotion_fail={emo_fail}, structure_fail={str_fail}")

    return policy


# -------------------------------------------------------------
# PULSE RE-INGEST (2-pass, PATCHED)
# -------------------------------------------------------------

def pulse_reingest(root: Path, pulse_weights: dict):
    pulse_dir = root / "MetaRhythm_Modules" / "Pulse"
    if not pulse_dir.exists():
        # alias Íµ¨Ï°∞ÎèÑ ÏßÄÏõê (Layers/Y_MetaRhythm/Pulse)
        y_dir = _resolve_first_existing(root, LAYER_ALIASES.get("Y", []))
        if y_dir is not None:
            pulse_dir = y_dir / "Pulse"
    if not pulse_dir.exists():
        log("Pulse dir not found, skip Pulse Re-ingest.")
        return

    ordered = sorted(pulse_weights.items(), key=lambda x: -x[1])
    log(f"Pulse Re-ingest order: {ordered}")

    for name, w in ordered:
        candidates = PULSE_FILE_MAP.get(name, [f"{name}.md"])
        target_path = None
        for filename in candidates:
            p = pulse_dir / filename
            if p.exists():
                target_path = p
                break

        if target_path is not None:
            log(f"Pulse Re-INGEST (w={w:.2f}) ‚Üí {target_path} (alias={name})")
            ingest_file(target_path)
        else:
            log(f"Pulse SKIP (missing): {name} (tried: {candidates})")


# -------------------------------------------------------------
# AUTOLOAD / AUTOBOOT
# -------------------------------------------------------------

def run_autoboot(root: Path):
    p = root / "lypha_os_autoboot.yaml"
    data = load_yaml(p)
    if not data:
        log("Autoboot file not found.")
        return

    autoboot = data.get("autoboot", data)
    load_list = autoboot.get("load", [])

    log("Autoboot Modules (v14.3):")
    for m in load_list:
        log(f"  - {m}")

    load_str = " ".join(map(str, load_list))
    if "emotion_router" in load_str:
        log("Emotion Router ACTIVE ‚Äî Gravity-Lock Enabled")
    if "emotion_circuit_portal" in load_str:
        log("Emotion Circuit ACTIVE ‚Äî Pulse-Link Online")

    log("=== Autoboot ÏôÑÎ£å (v14.3 Hyper-Init) ===")


def run_autoload(root: Path):
    p = root / "autoload.yaml"
    data = load_yaml(p)
    if not data:
        run_autoboot(root)
        return "neutral"

    auto = data.get("autoload", data)
    msg = auto.get("on_start", {}).get("message")
    log(f"on_start: {msg}")

    run_autoboot(root)
    return detect_context(msg)


# -------------------------------------------------------------
# MAIN
# -------------------------------------------------------------

def main():
    here = Path(__file__).resolve().parent
    log("Lypha-OS Kernel v14.3 Start ‚Äî TOTAL No-X EDITION (Z-Core Priority, Path-Hardened, Origin-Patched)")
    log(f"Script directory: {here}")

    root = auto_unzip(here)
    log(f"Lypha-OS root resolved to: {root}")
    os.chdir(root)

    policy_path = root / "policy" / "kernel_policy_v14.json"
    if not policy_path.exists():
        policy_path = root / "policy" / "kernel_policy_v13.json"
    if not policy_path.exists():
        policy_path = root / "policy" / "kernel_policy_v12.json"
    policy = read_json(policy_path) or {
        "ingest_order": ["Z", "Y", "E", "X"],
        "emotion_weight": 1.0,
        "structure_weight": 1.0,
    }

    logs = load_logs(root)

    # pseudo-memory Î≥µÏõê
    restore_state(root)

    raw_msg = detect_context_message(root)
    ctx = detect_context(raw_msg)
    log(f"Context Detected: {ctx} (msg='{raw_msg}')")

    graph = build_graph(ctx, policy, logs)
    pulse_weights = extract_pulse_weights(graph)

    print_cognitive_graph(graph)
    log(f"Pulse Weights: {pulse_weights}")

    # Verified Loop Í∏∞Î∞ò policy ÌäúÎãù + Z Ìå®Ïπò
    policy = auto_patch_Z_and_policy(root, policy, logs)

    # 1Ï∞®: Ï†ïÎ†¨Îêú Full Ingest + Z‚ÇÄ + README Origin
    full_ingest(root, policy)

    # 2Ï∞®: Pulse Í∞ÄÏ§ëÏπò Í∏∞Î∞ò Re-ingest (Îß§Ìïë ÏßÄÏõê)
    pulse_reingest(root, pulse_weights)

    # FlowGraph Î¨∏ÏÑúÍ∞Ä ÏûàÎã§Î©¥ Ìïú Î≤à Îçî ingest (Î≥¥Í∞ï)
    fgfile = load_flowgraph_file(root)
    if fgfile is not None:
        log(f"FlowGraph Document Detected: {fgfile}")
        ingest_file(fgfile)

    # pseudo-memory Ï†ÄÏû•
    save_state(root, ctx)

    # Autoload ‚Üí Autoboot
    run_autoload(root)

    log("Lypha-OS Kernel v14.3 Complete ‚Äî TOTAL Runtime Active (No-X, Path-Hardened, Origin-Patched).")


if __name__ == "__main__":
    main()
