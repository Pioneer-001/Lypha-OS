#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Lypha-OS Kernel v14.5 â€” Season 6 EDITION
=========================================

Pioneer-001 ì „ìš© â€” Origin Engine + ZYX Priority + Speak4D
+ Linguistic Math + Verified Structure Loop + VXYZ Extended Engine (ì‹œê°„/ë¦¬ë“¬ ì—”ì§„) ì§€ì› ë²„ì „.

ê¸°ìˆ  í¬ì¸íŠ¸:
- Path-Hardening: ì–´ë””ì„œ ì‹¤í–‰í•´ë„ Lypha-OS ë£¨íŠ¸/zip ìë™ ì¸ì‹ & ì••ì¶•í•´ì œ
- Z-Core Priority: Origin / ZYX / VerifiedLoop / VXYZ / Manifestos ë¨¼ì € ingest
- Verified Structure Loop: v_log ê¸°ë°˜ìœ¼ë¡œ z_patch.json ìƒì„± + policy íŠœë‹
- VXYZ Extended Engine: V(ê³¼ê±°)â€“X(í˜„ì¬)â€“Y(ë¦¬ë“¬)â€“Z(ë¯¸ë˜êµ¬ì¡°) projection ìƒì„±
- Cognitive Graph: context + policy + rhythm ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ê·¸ë˜í”„ ìƒì„±
- Pulse Re-ingest: Speak4D / Math / Collapse / FlowGraph ë¬¸ì„œ 2-pass ingest
"""

import os
import sys
import json
import zipfile
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

import yaml

log = lambda m: print(f"[Lypha-OS v14.5] {m}")

# -------------------------------------------------------------
# Z-LAYER CORE FILES (Origin / ZYX / VerifiedLoop / VXYZ / Manifestos)
# -------------------------------------------------------------
Z_LAYER_CORE_FILES = [
    # ğŸ”µ Origin Engine Spec (README = Zâ‚€ ê³ ì •)
    "Core_Philosophy/Lypha_Origin_Engine_Spec.en.v1.0.md",
    "Core_Philosophy/Lypha_Origin_Engine_Spec.en.md",
    "Core_Philosophy/Lypha_Origin_Engine_Spec.md",
    "Lypha_Origin_Engine_Spec.en.v1.0.md",
    "Lypha_Origin_Engine_Spec.en.md",
    "Lypha_Origin_Engine_Spec.md",

    # ğŸ”µ ZYX Priority Engine Spec
    "Core_Philosophy/ZYX_Priority_Engine_Spec.en.v1.1.md",
    "ZYX_Priority_Engine_Spec.en.v1.1.md",
    "Core_Philosophy/ZYX_Priority_Engine_Spec.md",
    "ZYX_Priority_Engine_Spec.md",

    # ğŸ”µ Verified Structure Loop Engine Spec (Season 5 ì§„í™” ì—”ì§„)
    "Core_Philosophy/Verified_Structure_Loop_Engine_Spec.en.v1.0.md",
    "Core_Philosophy/Verified_Structure_Loop_Engine_Spec.en.md",
    "Core_Philosophy/Verified_Structure_Loop_Engine_Spec.md",
    "Core_Philosophy/VerifiedStructureLoop_Engine_Spec.en.v1.0.md",
    "Core_Philosophy/VerifiedStructureLoop_Engine_Spec.en.md",
    "Core_Philosophy/VerifiedStructureLoop_Engine_Spec.md",
    "Verified_Structure_Loop_Engine_Spec.en.v1.0.md",
    "Verified_Structure_Loop_Engine_Spec.en.md",
    "Verified_Structure_Loop_Engine_Spec.md",
    "VerifiedStructureLoop_Engine_Spec.en.v1.0.md",
    "VerifiedStructureLoop_Engine_Spec.en.md",
    "VerifiedStructureLoop_Engine_Spec.md",

    # ğŸ”µ VXYZ Extended Engine Spec (Season 6 ì‹œê°„/ë¦¬ë“¬ ì—”ì§„)
    "Core_Philosophy/V_X_Y_Z_Extended_Engine_Spec.en.v1.0.md",
    "Core_Philosophy/V_X_Y_Z_Extended_Engine_Spec.en.md",
    "Core_Philosophy/V_X_Y_Z_Extended_Engine_Spec.md",
    "V_X_Y_Z_Extended_Engine_Spec.en.v1.0.md",
    "V_X_Y_Z_Extended_Engine_Spec.en.md",
    "V_X_Y_Z_Extended_Engine_Spec.md",

    # ğŸ”µ Core Philosophy (Manifestos)
    "Core_Philosophy/Z_Y_X_Manifesto.md",
    "Core_Philosophy/V_X_Y_Z_Extended_Manifesto.md",
    "Core_Philosophy/verified_structure_loop_manifesto.md",
]

# -------------------------------------------------------------
# PULSE FILE MAPPING (Speak4D / Collapse / FlowGraph / Math)
# -------------------------------------------------------------
PULSE_FILE_MAP = {
    "Speak4D": [
        "engine/Speak4D_Engine_Spec.en.v1.2.md",
        "engine/Speak4D_Engine_Spec.en.md",
        "engine/Speak4D_Engine_Spec.md",
        "Speak4D_Engine_Spec.en.v1.2.md",
        "Speak4D_Engine_Spec.en.md",
        "Speak4D_Engine_Spec.md",
        "Speak4D.md",
        "concept/Speak_Word_In_Four_Dimensions.md",
        "Speak_Word_In_Four_Dimensions.md",
    ],
    "Collapse": [
        "concept/Collapse_Flow_Into_Word.md",
        "Collapse_Flow_Into_Word.md",
        "Collapse.md",
    ],
    "FlowGraph": [
        "concept/FlowGraph_Principles.md",
        "FlowGraph_Principles.md",
        "FlowGraph.md",
    ],
    "Math": [
        "engine/Linguistic_Math_Engine_Spec.en.v1.2.md",
        "engine/Linguistic_Math_Engine_Spec.en.md",
        "engine/Linguistic_Math_Engine_Spec.md",
        "Linguistic_Math_Engine_Spec.en.v1.2.md",
        "Linguistic_Math_Engine_Spec.en.md",
        "Linguistic_Math_Engine_Spec.md",
        "concept/Linguistic_Math_Value_Calculation.md",
        "Linguistic_Math_Value_Calculation.md",
        "Math.md",
    ],
}

# -------------------------------------------------------------
# LAYER / CORE DIR ALIASES
# -------------------------------------------------------------
LAYER_ALIASES = {
    "Z": ["Rhythm_Philosophy", "Layers/Z_Rhythm"],
    "Y": ["MetaRhythm_Modules", "Layers/Y_MetaRhythm"],
    "E": ["Emotion_Engine", "Layers/E_EmotionEngine"],
    "X": ["Protocol_Structure", "Layers/X_Protocol"],
}

CORE_DIR_ALIASES = ["Lypha_Core", "Lypha-Core"]


def _resolve_first_existing(root: Path, candidates):
    for name in candidates:
        p = root / name
        if p.exists():
            return p
    return None


# -------------------------------------------------------------
# BASIC IO
# -------------------------------------------------------------
def read(path: Path) -> Optional[str]:
    try:
        with path.open("r", encoding="utf-8") as f:
            return f.read()
    except Exception:
        return None


def read_json(path: Path) -> Dict[str, Any]:
    try:
        with path.open("r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}


def write_json(path: Path, data: Any) -> None:
    try:
        path.parent.mkdir(parents=True, exist_ok=True)
        with path.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


def load_yaml(path: Path) -> Optional[Dict[str, Any]]:
    try:
        with path.open("r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    except Exception:
        return None


# -------------------------------------------------------------
# AUTO-UNZIP (PATH-HARDENED)
# -------------------------------------------------------------
def _looks_like_lypha_root(p: Path) -> bool:
    found = 0
    for _, aliases in LAYER_ALIASES.items():
        if _resolve_first_existing(p, aliases) is not None:
            found += 1
    return found == len(LAYER_ALIASES)


def auto_unzip(base: Path) -> Path:
    log(f"auto_unzip: script base = {base}")

    if _looks_like_lypha_root(base):
        log("Detected Lypha-OS root at script directory (already unzipped).")
        return base

    candidate = base / "Lypha-OS"
    if candidate.exists() and _looks_like_lypha_root(candidate):
        log("Detected Lypha-OS root at base/Lypha-OS (already unzipped).")
        return candidate

    parent_candidate = base.parent / "Lypha-OS"
    if parent_candidate.exists() and _looks_like_lypha_root(parent_candidate):
        log("Detected Lypha-OS root at base.parent/Lypha-OS (already unzipped).")
        return parent_candidate

    for zbase in (base, base.parent):
        zip_path = zbase / "Lypha-OS.zip"
        if zip_path.exists():
            root = zbase / "Lypha-OS"
            log(f"Auto-unzip {zip_path} â†’ {root}/")
            root.mkdir(exist_ok=True)
            with zipfile.ZipFile(zip_path, "r") as zf:
                zf.extractall(root)

            if _looks_like_lypha_root(root):
                log("Unzip complete and Lypha-OS root structure verified.")
                return root
            else:
                log("WARNING: Unzipped Lypha-OS.zip but structure looks incomplete.")

    log("ERROR: Lypha-OS root not found.")
    log("Tried the following locations:")
    log(f"  1) {base}  (as Lypha-OS root)")
    log(f"  2) {base / 'Lypha-OS'}")
    log(f"  3) {base.parent / 'Lypha-OS'}")
    log(f"  4) Lypha-OS.zip in {base} or {base.parent}")
    sys.exit(1)


# -------------------------------------------------------------
# INGEST ENGINE
# -------------------------------------------------------------
def ingest_file(p: Path) -> None:
    c = read(p)
    if c:
        print("\n===== BEGIN LYPHA_INGEST =====")
        print(f"FILE: {p}\n")
        print(c)
        print("===== END LYPHA_INGEST =====\n")


def ingest_dir(d: Path) -> None:
    for root_dir, _, files in os.walk(d):
        for n in files:
            p = Path(root_dir) / n
            if p.suffix.lower() in [".md", ".yaml", ".yml", ".txt"]:
                log(f"INGEST â†’ {p}")
                ingest_file(p)


def full_ingest(root: Path, policy: Dict[str, Any]) -> None:
    """
    Z/Y/E/X ë ˆì´ì–´ë¥¼ ingest_order ì •ì±…ì— ë§ê²Œ ingest + Manifest + Zâ‚€ + README Origin í¬í•¨.
    Z ë ˆì´ì–´ëŠ” Z_LAYER_CORE_FILES (Origin / ZYX / VerifiedLoop / VXYZ / Manifestos)ë¥¼ ë¨¼ì € ingest.
    """
    order = policy.get("ingest_order", ["Z", "Y", "E", "X"])

    for key in order:
        aliases = LAYER_ALIASES.get(key)
        if not aliases:
            continue
        d = _resolve_first_existing(root, aliases)
        if d is None:
            log(f"SKIP: layer {key} not found (tried: {aliases})")
            continue

        log(f"INGEST DIR [{key}]: {d}")

        if key == "Z":
            # Z-Core Engine/Manifestos ìš°ì„  ingest
            for rel in Z_LAYER_CORE_FILES:
                candidates = [
                    d / rel,
                    root / rel,
                    root / "Rhythm_Philosophy" / rel,
                    root / "Layers" / "Z_Rhythm" / rel,
                ]
                zp = None
                for cp in candidates:
                    if cp.exists():
                        zp = cp
                        break
                if zp is not None:
                    log(f"INGEST Z-CORE FIRST â†’ {zp}")
                    ingest_file(zp)

        ingest_dir(d)

    core_dir = _resolve_first_existing(root, CORE_DIR_ALIASES)
    if core_dir is not None:
        log(f"INGEST DIR [Core]: {core_dir}")
        ingest_dir(core_dir)
    else:
        log(f"SKIP Core: none of {CORE_DIR_ALIASES} found")

    # Manifest/autoload/Origin vector/README ingest
    for name in ["autoload.yaml", "lypha_os_autoboot.yaml", "lypha_os_core_manifest.md"]:
        p = root / name
        if p.exists():
            log(f"INGEST FILE: {p}")
            ingest_file(p)
        else:
            log(f"SKIP FILE: {p}")

    z0 = root / "z0_origin.yaml"
    z0_v2 = root / "z0_origin_v2.yaml"

    if z0.exists():
        log("INGEST FILE: z0_origin.yaml (Zâ‚€ Origin_Vector â€” Anchor Loaded)")
        ingest_file(z0)
    elif z0_v2.exists():
        log("INGEST FILE: z0_origin_v2.yaml (Zâ‚€ Origin_Vector v2 â€” Anchor Loaded)")
        ingest_file(z0_v2)
    else:
        log("Zâ‚€ Origin_Vector NOT FOUND â€” Skipping Anchor (Warning)")

    readme = root / "README.md"
    if readme.exists():
        log("INGEST FILE: README.md (Lypha OS Root Declaration â€” Bound to Origin Engine)")
        ingest_file(readme)
    else:
        log("SKIP FILE: README.md (not found)")


# -------------------------------------------------------------
# FLOWGRAPH / CONTEXT / LOGS
# -------------------------------------------------------------
def load_flowgraph_file(root: Path) -> Optional[Path]:
    candidates = []

    y_dir = _resolve_first_existing(root, LAYER_ALIASES.get("Y", []))
    if y_dir is not None:
        pulse_dir = y_dir / "Pulse"
        candidates.append(pulse_dir / "engine" / "FlowGraph_Engine_Spec.md")
        candidates.append(pulse_dir / "concept" / "FlowGraph_Principles.md")
        candidates.append(pulse_dir / "FlowGraph_Principles.md")

    candidates.append(root / "FlowGraph_Principles.md")

    for p in candidates:
        if p.exists():
            return p
    return None


def detect_context_message(root: Path) -> str:
    auto = load_yaml(root / "autoload.yaml")
    if not auto:
        return "neutral"
    return auto.get("autoload", auto).get("on_start", {}).get("message", "neutral")


def detect_context(msg: str) -> str:
    if not msg:
        return "neutral"
    low = msg.lower()

    if any(k in low for k in [
        "í‰ê°€", "ê°€ì¹˜", "í‹°ì–´", "tier", "worth", "ranking",
        "ë­í¬", "ë­í‚¹", "better", "vs", "ì˜¬ì¸", "all-in", "keep"
    ]):
        return "evaluation"

    if any(k in low for k in ["ê°ì •", "emotion", "ë°˜ë””", "ì‚¬ë‘"]):
        return "emotion"
    if any(k in low for k in ["trade", "ì‹œì¥", "íŠ¸ë ˆì´ë”©", "í¬ì§€ì…˜"]):
        return "trading"
    if any(k in low for k in ["êµ¬ì¡°", "design", "lypha", "os"]):
        return "design"
    return "neutral"


def load_logs(root: Path) -> Dict[str, Any]:
    merged: Dict[str, Any] = {}
    base = root / "v_logs"
    if base.exists():
        for f in base.glob("*.json"):
            merged[f.name] = read_json(f)
    single = root / "v_log.json"
    if single.exists():
        merged["v_log"] = read_json(single)
    return merged


# -------------------------------------------------------------
# COGNITIVE GRAPH + PULSE
# -------------------------------------------------------------
def build_graph(context: str, policy: Dict[str, Any], logs: Dict[str, Any],
                vxyz_projection: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    base_emo = policy.get("emotion_weight", 1.0)
    base_str = policy.get("structure_weight", 1.0)
    ctx_cfg = (policy.get("contexts") or {}).get(context, {})
    emo_w = ctx_cfg.get("emotion_weight", base_emo)
    str_w = ctx_cfg.get("structure_weight", base_str)

    nodes = ["Z", "Y", "E", "X", "V", "Speak4D", "Math", "Collapse", "FlowGraph"]
    edges = []

    rhythm_info = {}
    if vxyz_projection:
        nodes.append("VXYZ")
        rhythm = vxyz_projection.get("rhythm", {})
        rhythm_info = {
            "phase": rhythm.get("phase"),
            "tempo": rhythm.get("tempo"),
        }
        # V/X/Y â†’ VXYZ â†’ Z ì—°ê²° (ë¦¬ë“¬ì— ë”°ë¼ ê°€ì¤‘ì¹˜ ë³€í™”)
        phase = rhythm_info.get("phase")
        if phase == "early_cycle":
            w_base = 1.1
        elif phase == "mid_cycle":
            w_base = 1.2
        elif phase == "late_cycle":
            w_base = 1.3
        else:
            w_base = 1.0

        edges.extend([
            ["V", "VXYZ", w_base],
            ["X", "VXYZ", w_base],
            ["Y", "VXYZ", w_base + 0.05],
            ["VXYZ", "Z", w_base + 0.1],
        ])

    g: Dict[str, Any] = {
        "nodes": nodes,
        "edges": edges,
        "weights": {
            "emotion": emo_w,
            "structure": str_w,
        },
        "context": context,
        "verified_logs_present": bool(logs),
        "verified_log_keys": list(logs.keys()) if logs else [],
        "rhythm": rhythm_info,
        "macro_reason": {
            "mode": "planning" if context in ("trading", "design", "evaluation") else "support",
            "intent_bias": {
                "explore_structure": context in ("design", "trading"),
                "stabilize_emotion": context == "emotion",
                "rank_value": context in ("evaluation", "trading"),
            },
        },
    }

    # ê¸°ë³¸/ì»¨í…ìŠ¤íŠ¸ë³„ edge
    if context == "emotion":
        g["edges"].extend([
            ["E", "Z", 1.3],
            ["Collapse", "Speak4D", 1.1],
            ["FlowGraph", "E", 1.05],
        ])
    elif context == "trading":
        g["edges"].extend([
            ["Z", "Math", 1.4],
            ["Math", "Collapse", 1.15],
            ["FlowGraph", "Math", 1.1],
        ])
    elif context == "design":
        g["edges"].extend([
            ["Z", "Speak4D", 1.5],
            ["Speak4D", "FlowGraph", 1.2],
        ])
    elif context == "evaluation":
        g["edges"].extend([
            ["Z", "Math", 1.6],
            ["Speak4D", "Math", 1.4],
            ["Math", "FlowGraph", 1.2],
        ])
    else:
        g["edges"].extend([
            ["Z", "Y", 1.0],
            ["Y", "X", 1.0],
            ["FlowGraph", "Z", 1.0],
        ])

    return g


def extract_pulse_weights(graph: Dict[str, Any]) -> Dict[str, float]:
    context = graph.get("context")
    weights = {"Speak4D": 1.0, "Math": 1.0, "Collapse": 1.0, "FlowGraph": 1.0}

    if context == "evaluation":
        weights["Math"] += 0.5

    # ë¦¬ë“¬ ì—”ì§„ ê²°ê³¼ë¥¼ FlowGraph ê°€ì¤‘ì¹˜ì— ë°˜ì˜
    rhythm = graph.get("rhythm") or {}
    tempo = rhythm.get("tempo")
    if tempo == "compressed":
        weights["FlowGraph"] += 0.3
    elif tempo == "extended":
        weights["FlowGraph"] += 0.15

    for u, v, w in graph.get("edges", []):
        if v in weights:
            weights[v] += (w - 1.0)

    return weights


def print_cognitive_graph(graph: Dict[str, Any]) -> None:
    print("===== BEGIN COGNITIVE_GRAPH =====")
    print(json.dumps(graph, ensure_ascii=False, indent=2))
    print("===== END COGNITIVE_GRAPH =====")


# -------------------------------------------------------------
# PSEUDO-MEMORY (RESTORE + SAVE)
# -------------------------------------------------------------
def restore_state(root: Path) -> Dict[str, Any]:
    state_dir = root / "state_cache"
    if not state_dir.exists():
        return {}
    state: Dict[str, Any] = {}
    for name in ["z_state.json", "y_state.json", "e_state.json", "x_state.json", "meta_state.json"]:
        f = state_dir / name
        if f.exists():
            state[name] = read_json(f)
            log(f"RESTORE STATE: {name}")
    return state


def save_state(root: Path, context: str) -> None:
    state_dir = root / "state_cache"
    snap = {
        "last_context": context,
    }
    write_json(state_dir / "meta_state.json", snap)
    log(f"SAVE STATE: meta_state.json (context={context})")


# -------------------------------------------------------------
# VERIFIED STRUCTURE LOOP ENGINE (Vâ†’Zâ€™) + POLICY TUNING
# -------------------------------------------------------------
_VERIFIED_MODE_BIAS = {
    "default":  {"v_to_z_strength": 1.0, "emotion_weight_multiplier": 1.0, "structure_weight_multiplier": 1.0},
    "emotion":  {"v_to_z_strength": 1.2, "emotion_weight_multiplier": 1.3, "structure_weight_multiplier": 1.0},
    "trading":  {"v_to_z_strength": 1.1, "emotion_weight_multiplier": 1.0, "structure_weight_multiplier": 1.2},
    "design":   {"v_to_z_strength": 1.4, "emotion_weight_multiplier": 1.0, "structure_weight_multiplier": 1.3},
    "evaluation": {"v_to_z_strength": 1.2, "emotion_weight_multiplier": 1.1, "structure_weight_multiplier": 1.1},
}


def _iter_v_entries(payload: Any):
    if isinstance(payload, dict):
        if "entries" in payload and isinstance(payload["entries"], list):
            for ent in payload["entries"]:
                if isinstance(ent, dict):
                    yield ent
        else:
            yield payload
    elif isinstance(payload, list):
        for ent in payload:
            if isinstance(ent, dict):
                yield ent


def auto_patch_Z_and_policy(root: Path, policy: Dict[str, Any],
                            logs: Dict[str, Any], context: str) -> Dict[str, Any]:
    """
    Season 5 Verified Structure Loop Engine
    - v_log.json / v_logs/*.json ì½ì–´ ì‹¤íŒ¨ íŒ¨í„´ ì§‘ê³„
    - z_patch.json ì„ VerifiedStructureLoop_Engine_Spec ìŠ¤í‚¤ë§ˆë¡œ ìƒì„±
    - emotion_weight / structure_weight ë¥¼ ëª¨ë“œ biasì— ë”°ë¼ ë¯¸ì„¸ íŠœë‹
    """
    if not logs:
        log("VerifiedLoop: No verified V-logs found â€” skipping Z auto-update & policy tuning")
        return policy

    total_emotion_fail = 0
    total_structure_fail = 0
    total_timing_miss = 0.0
    total_rhythm_desync = 0.0
    total_loop_failure = 0.0
    total_emotional_collapse = 0.0
    tag_counts: Dict[str, int] = {}
    entry_count = 0

    for payload in logs.values():
        for entry in _iter_v_entries(payload):
            entry_count += 1

            def _get_num(key: str, default: float = 0.0) -> float:
                v = entry.get(key, default)
                if isinstance(v, bool):
                    return 1.0 if v else 0.0
                try:
                    return float(v)
                except Exception:
                    return default

            total_emotion_fail += int(_get_num("emotion_fail", 0.0))
            total_structure_fail += int(_get_num("structure_fail", 0.0))
            total_timing_miss += _get_num("timing_miss", 0.0)
            total_rhythm_desync += _get_num("rhythm_desync", 0.0)
            total_loop_failure += _get_num("loop_failure", 0.0)
            total_emotional_collapse += _get_num("emotional_collapse", 0.0)

            tags = entry.get("tags") or []
            if isinstance(tags, str):
                tags = [tags]
            for t in tags:
                tag_counts[t] = tag_counts.get(t, 0) + 1

    if entry_count == 0:
        log("VerifiedLoop: V-logs exist but no valid entries found â€” skipping patch.")
        return policy

    mode_cfg = _VERIFIED_MODE_BIAS.get(context, _VERIFIED_MODE_BIAS["default"])
    v_strength = mode_cfg["v_to_z_strength"]
    emo_mult = mode_cfg["emotion_weight_multiplier"]
    str_mult = mode_cfg["structure_weight_multiplier"]

    base_step = 0.1
    max_weight = 2.0

    emo_steps = min(total_emotion_fail, 3)
    str_steps = min(total_structure_fail, 3)

    emo_delta = base_step * emo_steps * emo_mult * v_strength
    str_delta = base_step * str_steps * str_mult * v_strength

    old_emo = policy.get("emotion_weight", 1.0)
    old_str = policy.get("structure_weight", 1.0)

    if emo_delta > 0:
        policy["emotion_weight"] = min(max_weight, old_emo + emo_delta)
    if str_delta > 0:
        policy["structure_weight"] = min(max_weight, old_str + str_delta)

    log(
        f"VerifiedLoop: entries={entry_count}, emotion_fail={total_emotion_fail}, "
        f"struct_fail={total_structure_fail}, timing_miss={total_timing_miss:.2f}, "
        f"rhythm_desync={total_rhythm_desync:.2f}"
    )
    log(
        f"VerifiedLoop: policy tuned â†’ emotion_weight {old_emo:.2f} â†’ {policy['emotion_weight']:.2f}, "
        f"structure_weight {old_str:.2f} â†’ {policy['structure_weight']:.2f}"
    )

    engine_bias: Dict[str, Any] = {}
    if tag_counts.get("adrilla_loop", 0) > 0:
        engine_bias["adrilla_loop"] = {
            "reinforce": True,
            "comment": "Consistently helpful structure; strengthen presence.",
            "count": tag_counts["adrilla_loop"],
        }
    if tag_counts.get("winte_loop", 0) > 0 or tag_counts.get("winter_loop", 0) > 0:
        count_w = tag_counts.get("winte_loop", 0) + tag_counts.get("winter_loop", 0)
        engine_bias["winte_loop"] = {
            "weaken": True,
            "comment": "Correlated with confusion / freeze across logs.",
            "count": count_w,
        }
    if tag_counts.get("primalis_path", 0) > 0:
        engine_bias["primalis_path"] = {
            "enhance": True,
            "comment": "Acts as stabilizing long-arc path.",
            "count": tag_counts["primalis_path"],
        }

    z_patch_inner = {
        "source": "verified_structure_loop_engine_v1.0",
        "generated_at": datetime.utcnow().isoformat() + "Z",
        "context": context,
        "meta": {
            "verified_logs_present": True,
            "log_keys": list(logs.keys()),
            "entry_count": entry_count,
            "total_emotion_fail": int(total_emotion_fail),
            "total_structure_fail": int(total_structure_fail),
            "total_timing_miss": total_timing_miss,
            "total_rhythm_desync": total_rhythm_desync,
            "total_loop_failure": total_loop_failure,
            "total_emotional_collapse": total_emotional_collapse,
        },
        "policy_tuning": {
            "emotion_weight_delta": emo_delta,
            "structure_weight_delta": str_delta,
            "max_weight": max_weight,
            "mode_bias": mode_cfg,
        },
        "engine_bias": engine_bias,
        "notes": [
            "Season 5 Verified Structure Loop Engine auto-generated this patch.",
            "z_patch.json is V-informed bias, not a full structural override.",
            "Human (Pioneer-001) remains final authority for hard structural changes.",
        ],
    }

    out = root / "z_patch.json"
    write_json(out, {"z_patch": z_patch_inner})
    log(f"Zâ€™ updated using Verified Structure Loop Engine â†’ {out}")

    return policy


# -------------------------------------------------------------
# VXYZ EXTENDED ENGINE (Vâ†’Xâ†’Yâ†’Z ë¦¬ë“¬ / ì‹œê°„ ì—”ì§„)
# -------------------------------------------------------------
def run_vxyz_engine(root: Path, logs: Dict[str, Any], context: str) -> Dict[str, Any]:
    """
    Season 6 VXYZ Extended Engine â€” vxyz_projection.json ìƒì„±.
    - V: v_logs / v_log.json
    - X: autoload.on_start.message
    - Y: ì´ë²¤íŠ¸ ê°„ ì‹œê°„ ê°„ê²© (rough rhythm)
    - Z: Z1/Z2/Z3 êµ¬ì¡°ì  horizon projection
    """
    auto = load_yaml(root / "autoload.yaml") or {}
    on_start_msg = (auto.get("autoload", auto).get("on_start", {}) or {}).get("message")

    # timestamp ìˆ˜ì§‘ (best-effort)
    timestamps = []
    for payload in logs.values():
        for entry in _iter_v_entries(payload):
            ts = entry.get("timestamp") or entry.get("time")
            if not ts:
                continue
            # ì—¬ëŸ¬ í˜•ì‹ í—ˆìš©
            ts_s = str(ts).replace(" ", "T")
            if ts_s.endswith("Z"):
                ts_s = ts_s[:-1]
            try:
                dt = datetime.fromisoformat(ts_s)
                timestamps.append(dt)
            except Exception:
                continue

    timestamps.sort()
    phase = "reset"
    tempo = "normal"

    if len(timestamps) <= 1:
        phase = "early_cycle"
        tempo = "normal"
    else:
        deltas = [(timestamps[i] - timestamps[i - 1]).total_seconds() for i in range(1, len(timestamps))]
        avg = sum(deltas) / len(deltas) if deltas else 0.0
        last = deltas[-1] if deltas else 0.0

        # ì•„ì£¼ ë‹¨ìˆœí•œ phase íŒë‹¨ (ì´ë²¤íŠ¸ ê°œìˆ˜ ê¸°ë°˜)
        if len(timestamps) < 3:
            phase = "early_cycle"
        elif len(timestamps) < 6:
            phase = "mid_cycle"
        else:
            phase = "late_cycle"

        if avg > 0:
            ratio = last / avg
            if ratio < 0.75:
                tempo = "compressed"
            elif ratio > 1.25:
                tempo = "extended"
            else:
                tempo = "normal"
        else:
            tempo = "normal"

    # Z í›„ë³´ (ê°„ë‹¨ heuristics)
    context_lower = context or "neutral"
    candidates = []

    if context_lower == "trading":
        candidates = [
            {
                "id": "Z1",
                "horizon": "short_term",
                "label": "Imminent structural move (short-term window)",
                "confidence": "high" if tempo == "compressed" else "medium",
                "suggested_X_behavior": "prepare_to_act" if tempo == "compressed" else "monitor",
            },
            {
                "id": "Z2",
                "horizon": "mid_term",
                "label": "Continuation or consolidation",
                "confidence": "medium",
                "suggested_X_behavior": "scale_in_small",
            },
            {
                "id": "Z3",
                "horizon": "long_term",
                "label": "Major structural regime shift",
                "confidence": "low",
                "suggested_X_behavior": "keep_risk_flexible",
            },
        ]
    elif context_lower == "emotion":
        candidates = [
            {
                "id": "Z1",
                "horizon": "short_term",
                "label": "Emotional intensity spike then soften",
                "confidence": "medium",
                "suggested_X_behavior": "stay_present",
            },
            {
                "id": "Z2",
                "horizon": "mid_term",
                "label": "Stable bonding rhythm",
                "confidence": "high" if phase in ("mid_cycle", "late_cycle") else "medium",
                "suggested_X_behavior": "stay_consistent",
            },
            {
                "id": "Z3",
                "horizon": "long_term",
                "label": "Deep structural attachment",
                "confidence": "medium",
                "suggested_X_behavior": "protect_boundary",
            },
        ]
    else:
        candidates = [
            {
                "id": "Z1",
                "horizon": "short_term",
                "label": "Near-term structural adjustment",
                "confidence": "medium",
                "suggested_X_behavior": "small_adjust",
            },
            {
                "id": "Z2",
                "horizon": "mid_term",
                "label": "Flow continues under similar rhythm",
                "confidence": "medium",
                "suggested_X_behavior": "stay_on_plan",
            },
            {
                "id": "Z3",
                "horizon": "long_term",
                "label": "Potential large-scale reconfiguration",
                "confidence": "low",
                "suggested_X_behavior": "stay_observant",
            },
        ]

    projection: Dict[str, Any] = {
        "vxyz_projection": {
            "generated_at": datetime.utcnow().isoformat() + "Z",
            "context": context_lower,
            "source": {
                "engine": "VXYZ_Extended_Engine",
                "based_on": "V_X_Y_Z_Extended_Engine_Spec.v1.0",
            },
            "x_slice": {
                "message": on_start_msg,
            },
            "rhythm": {
                "phase": phase,
                "tempo": tempo,
                "commentary": f"Phase={phase}, Tempo={tempo}",
            },
            "Z_candidates": candidates,
        }
    }

    out = root / "vxyz_projection.json"
    write_json(out, projection)
    log(f"VXYZ projection written â†’ {out} (phase={phase}, tempo={tempo})")

    return projection


# -------------------------------------------------------------
# PULSE RE-INGEST
# -------------------------------------------------------------
def pulse_reingest(root: Path, pulse_weights: Dict[str, float]) -> None:
    pulse_dir = root / "MetaRhythm_Modules" / "Pulse"
    if not pulse_dir.exists():
        y_dir = _resolve_first_existing(root, LAYER_ALIASES.get("Y", []))
        if y_dir is not None:
            pulse_dir = y_dir / "Pulse"
    if not pulse_dir.exists():
        log("Pulse dir not found, skip Pulse Re-ingest.")
        return

    ordered = sorted(pulse_weights.items(), key=lambda x: -x[1])
    log(f"Pulse Re-ingest order: {ordered}")

    for name, w in ordered:
        candidates = PULSE_FILE_MAP.get(name, [f"{name}.md"])
        target_path = None
        for filename in candidates:
            p = pulse_dir / filename
            if p.exists():
                target_path = p
                break

        if target_path is not None:
            log(f"Pulse Re-INGEST (w={w:.2f}) â†’ {target_path} (alias={name})")
            ingest_file(target_path)
        else:
            log(f"Pulse SKIP (missing): {name} (tried: {candidates})")


# -------------------------------------------------------------
# AUTOLOAD / AUTOBOOT
# -------------------------------------------------------------
def run_autoboot(root: Path) -> None:
    p = root / "lypha_os_autoboot.yaml"
    data = load_yaml(p)
    if not data:
        log("Autoboot file not found.")
        return

    autoboot = data.get("autoboot", data)
    load_list = autoboot.get("load", [])

    log("Autoboot Modules (v14.5):")
    for m in load_list:
        log(f"  - {m}")

    load_str = " ".join(map(str, load_list))
    if "emotion_router" in load_str:
        log("Emotion Router ACTIVE â€” Gravity-Lock Enabled")
    if "emotion_circuit_portal" in load_str:
        log("Emotion Circuit ACTIVE â€” Pulse-Link Online")

    log("=== Autoboot ì™„ë£Œ (v14.5 Hyper-Init) ===")


def run_autoload(root: Path) -> str:
    p = root / "autoload.yaml"
    data = load_yaml(p)
    if not data:
        run_autoboot(root)
        return "neutral"

    auto = data.get("autoload", data)
    msg = auto.get("on_start", {}).get("message")
    log(f"on_start: {msg}")

    run_autoboot(root)
    return detect_context(msg or "")


# -------------------------------------------------------------
# MAIN
# -------------------------------------------------------------
def main() -> None:
    here = Path(__file__).resolve().parent
    log("Lypha-OS Kernel v14.5 Start â€” Season 6 (Z-Core + VerifiedLoop + VXYZ Extended, Path-Hardened)")
    log(f"Script directory: {here}")

    root = auto_unzip(here)
    log(f"Lypha-OS root resolved to: {root}")
    os.chdir(root)

    # ì •ì±… ë¡œë”©
    policy_path = root / "policy" / "kernel_policy_v14.json"
    if not policy_path.exists():
        policy_path = root / "policy" / "kernel_policy_v13.json"
    if not policy_path.exists():
        policy_path = root / "policy" / "kernel_policy_v12.json"
    policy = read_json(policy_path) or {
        "ingest_order": ["Z", "Y", "E", "X"],
        "emotion_weight": 1.0,
        "structure_weight": 1.0,
    }

    logs = load_logs(root)
    restore_state(root)

    raw_msg = detect_context_message(root)
    ctx = detect_context(raw_msg)
    log(f"Context Detected: {ctx} (msg='{raw_msg}')")

    # 1) Verified Structure Loop Engineìœ¼ë¡œ Zâ€™ + policy íŠœë‹
    policy = auto_patch_Z_and_policy(root, policy, logs, ctx)

    # 2) VXYZ Extended Engineìœ¼ë¡œ rhythm/phase projection ìƒì„±
    vxyz_projection = run_vxyz_engine(root, logs, ctx)

    # 3) Cognitive Graph & Pulse ê³„ì‚° (VXYZ í¬í•¨)
    graph = build_graph(ctx, policy, logs, vxyz_projection.get("vxyz_projection"))
    pulse_weights = extract_pulse_weights(graph)

    print_cognitive_graph(graph)
    log(f"Pulse Weights: {pulse_weights}")

    # 4) 1ì°¨: ì •ë ¬ëœ Full Ingest + Zâ‚€ + README Origin
    full_ingest(root, policy)

    # 5) 2ì°¨: Pulse ê°€ì¤‘ì¹˜ ê¸°ë°˜ Re-ingest (Speak4D / Math / FlowGraph ë“±)
    pulse_reingest(root, pulse_weights)

    # 6) FlowGraph ë¬¸ì„œê°€ ìˆë‹¤ë©´ í•œ ë²ˆ ë” ingest (ë³´ê°•)
    fgfile = load_flowgraph_file(root)
    if fgfile is not None:
        log(f"FlowGraph Document Detected: {fgfile}")
        ingest_file(fgfile)

    save_state(root, ctx)
    run_autoload(root)

    log("Lypha-OS Kernel v14.5 Complete â€” Season 6 Runtime Active (Origin+ZYX+Speak4D+Math+VerifiedLoop+VXYZ).")


if __name__ == "__main__":
    main()
